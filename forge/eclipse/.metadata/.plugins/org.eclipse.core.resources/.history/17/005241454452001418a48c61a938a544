package com.parmandorc.LearningMobs;

import java.util.HashMap;

import com.parmandorc.LearningMobs.AI.LMAIBase;

import net.minecraft.block.Block;
import net.minecraft.block.BlockAir;
import net.minecraft.block.BlockFence;
import net.minecraft.block.BlockStaticLiquid;
import net.minecraft.enchantment.EnchantmentHelper;
import net.minecraft.entity.Entity;
import net.minecraft.entity.EntityCreature;
import net.minecraft.entity.EntityLiving;
import net.minecraft.entity.EntityLivingBase;
import net.minecraft.entity.SharedMonsterAttributes;
import net.minecraft.entity.ai.EntityAINearestAttackableTarget;
import net.minecraft.entity.ai.EntityAISwimming;
import net.minecraft.entity.ai.EntityAIWatchClosest;
import net.minecraft.entity.player.EntityPlayer;
import net.minecraft.init.Items;
import net.minecraft.item.ItemStack;
import net.minecraft.nbt.NBTTagCompound;
import net.minecraft.util.DamageSource;
import net.minecraft.util.MathHelper;
import net.minecraft.world.World;

public abstract class EntityLearningMob extends EntityCreature
{
	//Array of tasks a LMob is able to use.
	protected LMAIBase[] LMTasks;
	//Pointers to the positions in LMTasks array of the currently executing task, and the next task that should execute, respectively.
	private int currentTask, nextTask;
	//Battle states saved before and after the current task's execution, respectively.
	private State prevState, curState;
	//Value used in the Q-learning algorithm. The higher this value, the faster the learning is.
	private static final double QLearningRate = 0.2;
	//Value used in the Q-learning algorithm. The higher this value, the higher the impact of the maximum expected reward will be.
	private static final double QDiscountFactor = 0.15;
	private static final double QRandomDiscountFactor = 0.99999;
	
	public static boolean autoRespawningEnabled = false;
	private boolean needsRespawning = false;
	private boolean justKilledTarget = false;

	protected static final double meleeRange = 3.5;
	protected static final double rangedRange = 15;
	
	public static boolean PVEEnabled;
	private EntityAINearestAttackableTarget targetPlayers;
	private EntityAINearestAttackableTarget targetOtherLM;
	private EntityAINearestAttackableTarget currentTargeting;


	//Group of parameters used for comparison of battle values
	private class State{
		EntityLearningMob owner;
		float targetsHealth = 0;
		float targetsMaxHealth = 10;
		float ownersHealth;
		float distanceToTarget;
		
		//Constructor
		public State(EntityLearningMob owner, EntityLivingBase target)
		{
			this.owner = owner;
			this.ownersHealth = owner.getHealth();
			if (target != null)
			{
				this.targetsHealth = target.getHealth();
				this.targetsMaxHealth = target.getMaxHealth();
				this.distanceToTarget = owner.getDistanceToEntity(target);
			}
		}
		
		//Getters
		public float getOwnersHealth(){	return ownersHealth; }
		
		public float getTargetsHealth(){ return targetsHealth; }
		
		public float getTargetsMaxHealth(){ return targetsMaxHealth; }
		
		public float getDistanceToTarget(){ return distanceToTarget; }
	}
	
	//Constructor
	public EntityLearningMob(World p_i1738_1_) 
	{
		super(p_i1738_1_);

		//Tasks common to all LMobs, independently of their class.
		this.tasks.addTask(1, new EntityAISwimming(this));
		this.targetPlayers = new EntityAINearestAttackableTarget(this, EntityPlayer.class, 0, false);
		this.targetOtherLM = new EntityAINearestAttackableTarget(this, EntityLearningMob.class, 0, false);
		currentTargeting = PVEEnabled ? targetPlayers : targetOtherLM;
		this.targetTasks.addTask(1, currentTargeting);

		//Initialization of pointers for correct management of LMTasks array. This means no task has been executed or chosen yet.
		currentTask = nextTask = -1;
		
		Q_values_init();
		
		//Prevents entity from naturally despawning
		this.func_110163_bv();
	}

	/*
	 * Needed to avoid issues with entity not completely respawning if hit in the autorespawn process.
	 */
	@Override
    public boolean isEntityInvulnerable()
    {
        return this.needsRespawning;
    }
    
	//Returns the currently executing task, or -1 if none has executed yet.
	private LMAIBase getCurrentTask()
	{
		return (currentTask == -1) ? null : LMTasks[currentTask];
	}
	
    protected void applyEntityAttributes()
    {
        super.applyEntityAttributes();
        this.getAttributeMap().registerAttribute(SharedMonsterAttributes.attackDamage);
        this.getEntityAttribute(SharedMonsterAttributes.followRange).setBaseValue(50.0D);
        this.getEntityAttribute(SharedMonsterAttributes.maxHealth).setBaseValue(20.0D);
        this.getEntityAttribute(SharedMonsterAttributes.movementSpeed).setBaseValue(0.2D);
    }
    
    public void writeEntityToNBT(NBTTagCompound nbt)
    {
        super.writeEntityToNBT(nbt);

        nbt.setDouble("QRandomSelectionRate", this.getQRandomSelectionRate());
        nbt.setBoolean("PVEEnabled", PVEEnabled);
    }
    
    public void readEntityFromNBT(NBTTagCompound nbt)
    {
        super.readEntityFromNBT(nbt);

        double qrsr = nbt.getDouble("QRandomSelectionRate");
        this.setQRandomSelectionRate(qrsr == 0 ? 1 : qrsr);
        this.PVEEnabled = nbt.getBoolean("PVEEnabled");
    }
  
    
	public boolean attackEntityAsMob(Entity p_70652_1_)
	{
        float f = (float)this.getEntityAttribute(SharedMonsterAttributes.attackDamage).getAttributeValue();
        
//        int i = 0;
//
//        if (p_70652_1_ instanceof EntityLivingBase)
//        {
//            f += EnchantmentHelper.getEnchantmentModifierLiving(this, (EntityLivingBase)p_70652_1_);
//            i += EnchantmentHelper.getKnockbackModifier(this, (EntityLivingBase)p_70652_1_);
//        }

        boolean flag = p_70652_1_.attackEntityFrom(DamageSource.causeMobDamage(this), f);

//        if (flag)
//        {
//            if (i > 0)
//            {
//                p_70652_1_.addVelocity((double)(-MathHelper.sin(this.rotationYaw * (float)Math.PI / 180.0F) * (float)i * 0.5F), 0.1D, (double)(MathHelper.cos(this.rotationYaw * (float)Math.PI / 180.0F) * (float)i * 0.5F));
//                this.motionX *= 0.6D;
//                this.motionZ *= 0.6D;
//            }
//
//            int j = EnchantmentHelper.getFireAspectModifier(this);
//
//            if (j > 0)
//            {
//                p_70652_1_.setFire(j * 4);
//            }
//
//            if (p_70652_1_ instanceof EntityLivingBase)
//            {
//                EnchantmentHelper.func_151384_a((EntityLivingBase)p_70652_1_, this);
//            }
//
//            EnchantmentHelper.func_151385_b(this, p_70652_1_);
//        }

        return flag;
	}
	
	@Override
	public void onUpdate()
	{
		if ((PVEEnabled && currentTargeting == targetOtherLM) || (!PVEEnabled && currentTargeting == targetPlayers))
		{
			this.targetTasks.removeTask(currentTargeting);
			currentTargeting = PVEEnabled ? targetPlayers : targetOtherLM;
			this.targetTasks.addTask(1, currentTargeting);
		}
		super.onUpdate();
	}
	
	protected boolean isAIEnabled()
	{
		return true;
	}
	
	protected void updateAITick()
	{		
		if (needsRespawning)
		{
			this.setHealth(0);
			currentTask = -1;
			nextTask = -1;
			return;
		}
		
		if (this.getAttackTarget() == null && !justKilledTarget)
			return;
		
		if (currentTask == -1) //LM just spawned and has no LMTask started.
		{
			curState = new State(this, this.getAttackTarget());
			obtainNextTask();
			currentTask = nextTask;
			this.tasks.addTask(5, getCurrentTask());
			prevState = curState;
		}
		else if (getCurrentTask().hasFinished()) //Q-learning algorithm iterates once the current task has finished.
		{
			//Obtain this entities state after finished task
			this.curState = new State(this, this.getAttackTarget());
			
			//Obtain reward based on the states after and before executing the task.
			double reward = obtainReward();
			
			//Update Q_values based on reward
			updateQ_Values(reward);
			
			if (justKilledTarget) //If justKilledTarget, it will have to select a new target in next iteration. This one has thus finished.
			{
				nextTask = -1;
				currentTask = -1;
				justKilledTarget = false;
				return;
			}
			
			//Obtain task for new iteration based on current state and Q_values table.
			obtainNextTask();
			
			//Replacement of the task that should execute.
			if (currentTask == nextTask) //Optimization in case it is not necessary to replace the current task.
			{
				getCurrentTask().reset();
			}
			else
			{
				this.tasks.removeTask(getCurrentTask());
				currentTask = nextTask;
				getCurrentTask().reset();
				this.tasks.addTask(5, getCurrentTask());
			}
			
			//Save the state for comparison in next iteration.
			prevState = curState;
		}
	}
	
	
	/* Obtains a reward based on the states before and after executing a task.
	 * Takes into account the variation in this entity's life and the enemy's life. */
	private double obtainReward()
	{
		return justKilledTarget ? 10 : curState.getOwnersHealth() - prevState.getOwnersHealth() +
				prevState.getTargetsHealth() - curState.getTargetsHealth();
	}
	
	//Updates the value for the current state and the just finished task in the Q_values table, based on the obtained reward.
	private void updateQ_Values(double reward)
	{
		int key = getQKey(getQState(prevState),currentTask);
		double qvalue = getQ_Values().containsKey(key) ? getQ_Values().get(key) : 0;
		int maxEstimateKey = getQKey(getQState(curState),getTaskWithMaxQValue(curState));
		double maxEstimate = getQ_Values().containsKey(maxEstimateKey) ? getQ_Values().get(maxEstimateKey) : 0;
		
		qvalue += QLearningRate * (reward + QDiscountFactor * maxEstimate - qvalue);
		
		getQ_Values().put(key, qvalue);
		setQIterations(getQIterations() + 1);
	}
	
	/* Selects a new task for the next iteration.
	 * It can return a random task or the task with the highest expected reward for the current state,
	 * based on the Q_value of this 'best' task (the higher this value, the higher the possibility of using this task.*/
	private void obtainNextTask()
	{
		if (this.rand.nextDouble() < getQRandomSelectionRate())
			nextTask = this.rand.nextInt(getTotalLMTasks());
		else
		{
			int bestTask = getTaskWithMaxQValue(curState);
			int key = getQKey(getQState(curState), bestTask);
			double qvalue = getQ_Values().containsKey(key) ? getQ_Values().get(key) : 0;
			nextTask = bestTask;
		}

		setQRandomSelectionRate(getQRandomSelectionRate() * QRandomDiscountFactor);
	}
	
	/* Designates the state passed as parameter a unique id value, different from every state.
	 * Takes into account the distance to target, the life of this entity and the life of the enemy.
	 */
	private int getQState(State state)
	{
		return getDistanceState(state.getDistanceToTarget()) * 9 + getHPState(state.getOwnersHealth(),this.getMaxHealth()) * 3 + 
				getHPState(state.getTargetsHealth(),state.getTargetsMaxHealth());
	}
	
	//Designates a unique id value to the combination of a state and a task. This will be the key in the Q_values table.
	private int getQKey(int state, int task)
	{
		return state * getTotalLMTasks() + task;
	}
	
	//Returns the task with the highest expected reward (in the Q_values table) for passed state.
	private int getTaskWithMaxQValue(State state)
	{
		int task = 0;
		double maxvalue = 0;
		int i = 0;
		int key =  getQKey(getQState(state), 0);
		do
		{
			double qvalue = getQ_Values().containsKey(key) ? getQ_Values().get(key) : 0;
			if (maxvalue < qvalue)
			{
				maxvalue = qvalue;
				task = i;
			}
			i++;
			key++;
		} while (i < getTotalLMTasks());
		return task;
	}
	
	/* Designates a unique id value to the distance passed.
	 * At a higher level, it divides the possibilities of distance between entity and enemy in three levels: out of range, ranged range or melee range.*/
	private int getDistanceState(float distance)
	{
		return (distance < meleeRange) ? 0 : (distance < rangedRange) ? 1 : 2;
	}
	
	/* Designates a unique id value to a certain HP value, based on the max HP value possible.
	 * At a higher level, it divides the HP bar of an entity in three levels: high, medium or low health. */
	private int getHPState(float health, float maxHealth)
	{
		float HPpercent = health / maxHealth;
		return (HPpercent == 1) ? 2 : (int)((HPpercent * 10 - 1) / 3);
	}
	
	protected void onDeathUpdate()
	{
		super.onDeathUpdate();

		if (this.autoRespawningEnabled)
		{
			if (deathTime == 10) //This must be done before tick 20, since the reposition has to be done will invulnerable to avoid issues
			{
				EntityLivingBase target = this.getAttackTarget();
				if (this.worldObj != null &&  target != null)
				{
					//Respawn in a near random position around target
					double maxDistance = this.getEntityAttribute(SharedMonsterAttributes.followRange).getBaseValue()*0.6;
					boolean positioned = false;
					while(!positioned)
					{
						double newPosX = target.posX + this.rand.nextDouble() * maxDistance*2 - maxDistance;
						double newPosY = target.posY;
						double newPosZ = target.posZ + this.rand.nextDouble() * maxDistance*2 - maxDistance;
						do
						{
							this.setPosition(newPosX, newPosY, newPosZ);
							newPosY++;
						} 
						while (this.getDistanceToEntity(target) < maxDistance && !this.worldObj.getCollidingBoundingBoxes(this, this.boundingBox).isEmpty());
						
						if (this.worldObj.getCollidingBoundingBoxes(this, this.boundingBox).isEmpty() && canRespawnHere())
							positioned = true;
					} 
				}
			}
			else if (deathTime == 20)
				handleAutoRespawn();
		}
    }
	
	private boolean canRespawnHere()
	{
		int x = this.posX >= 0 ? (int)this.posX : (int)this.posX - 1;
		int z = this.posZ >= 0 ? (int)this.posZ : (int)this.posZ - 1;
		Block blockUnderThis = this.worldObj.getBlock(x, (int)this.posY, z);
		for (int i = (int)this.posY; i > -64 && blockUnderThis instanceof BlockAir; i--)
			blockUnderThis = this.worldObj.getBlock(x, i, z);
				
		return !(blockUnderThis instanceof BlockStaticLiquid) && !(blockUnderThis instanceof BlockFence);
	}
    
	public void onDeath(DamageSource p_70645_1_)
	{
		super.onDeath(p_70645_1_);

		 //Will make a final iteration in the q-learning algorithm to earn a negative reward
		if (prevState != null)
		{
			this.curState = new State(this, this.getAttackTarget());
			if (!this.justKilledTarget) //If justKilledTarget, it will take max and min reward, which equals reward = 0, so there's no need to update qvalues
				updateQ_Values(-10);
			else
				justKilledTarget = false;
			nextTask = -1;
			currentTask = -1;
		}
		
		if (this.autoRespawningEnabled)
			handleAutoRespawn();
	}
	
	private void handleAutoRespawn()
	{
		this.isDead = false;
		this.deathTime = 0;
		this.hurtTime = 0;
		this.setHealth(10);
		this.needsRespawning = !this.needsRespawning;
	}
	
	public void onKillEntity(EntityLivingBase p_70074_1_)
	{
		super.onKillEntity(p_70074_1_);
		
		this.justKilledTarget = true;
	}
	
	protected boolean interact(EntityPlayer p_70085_1_)
	{
		ItemStack itemstack = p_70085_1_.getCurrentEquippedItem();
        if (itemstack != null && itemstack.getItem() == Items.stick)
        {
        	System.out.println(this + " HP: "+this.getHealth()+"/"+this.getMaxHealth());
        	return true;
        }
        if (itemstack != null && itemstack.getItem() == Items.blaze_rod)
        {
        	System.out.println("QIterations = "+getQIterations() + ", QRandomSelectionRate = "+getQRandomSelectionRate());
        	System.out.println("PRINTING Q_VALUES BY TASKS");
        	String text = "";
        	for (int i = 0; i < getTotalLMTasks(); i++)
        	{
        		text = "Task #" + i + ": ";
        		for (int j = i; j < 81; j+=3)
        		{
        			if (getQ_Values().containsKey(j))
        				text += j + ":" + getQ_Values().get(j) + " ";
        		}
        		System.out.println(text);
        	}
        	return true;
        }
        if (itemstack != null && itemstack.getItem() == Items.arrow)
        {
        	System.out.println("QIterations = "+getQIterations() + ", QRandomSelectionRate = "+getQRandomSelectionRate());
        	System.out.println("PRINTING Q_VALUES");
        	System.out.println(getQ_Values().toString());
        	return true;
        }
		return false;
	}
	
	protected abstract HashMap<Integer,Double> getQ_Values();
	protected abstract int getTotalLMTasks();
	protected abstract void Q_values_init();
	protected abstract double getQRandomSelectionRate();
	protected abstract void setQRandomSelectionRate(double value);
	protected abstract int getQIterations();
	protected abstract void setQIterations(int value);
}
